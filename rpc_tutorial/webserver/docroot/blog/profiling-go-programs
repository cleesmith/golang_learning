
<!DOCTYPE html>
<html>
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<title>Profiling Go Programs - The Go Blog</title>
	<link type="text/css" rel="stylesheet" href="/lib/godoc/style.css">
	<link rel="alternate" type="application/atom+xml" title="blog.golang.org - Atom Feed" href="//blog.golang.org/feed.atom" />
	<script type="text/javascript">window.initFuncs = [];</script>
	<style>
		#sidebar {
			float: right;
			padding-left: 20px;
			width: 250px;
			background: white;
		}
		#sidebar p, #sidebar ul {
			margin: 20px 5px;
		}
		#sidebar ul {
			padding: 0;
		}
		#sidebar li {
			list-style-type: none;
		}
		#content .author {
			font-style: italic;
		}
		#content .article {
			margin-bottom: 50px;
		}
		#content .date {
			color: #999;
		}
		#content .tags {
			color: #999;
			font-size: smaller;
		}
		#content .iframe, #content .image {
			margin: 20px;
		}
		#content .title {
			margin: 20px 0;
		}
	</style>
<script type="text/javascript">
var _gaq = _gaq || [];
_gaq.push(["_setAccount", "UA-11222381-3"]);
_gaq.push(["b._setAccount", "UA-49880327-6"]);
window.trackPageview = function() {
  _gaq.push(["_trackPageview", location.pathname+location.hash]);
  _gaq.push(["b._trackPageview", location.pathname+location.hash]);
};
window.trackPageview();
</script>
</head>
<body>

<div id="topbar"><div class="container">

<form method="GET" action="//golang.org/search">
<div id="menu">
<a href="//golang.org/doc/">Documents</a>
<a href="//golang.org/pkg/">Packages</a>
<a href="//golang.org/project/">The Project</a>
<a href="//golang.org/help/">Help</a>
<a href="/">Blog</a>
<input type="text" id="search" name="q" class="inactive" value="Search" placeholder="Search">
</div>
<div id="heading"><a href="//golang.org/">The Go Programming Language</a></div>
</form>

</div></div>

<div id="page">
<div class="container">

<div id="sidebar">
	
		
			<h4>Next article</h4>
			<p><a href="/first-class-functions-in-go-and-new-go">&#34;First Class Functions in Go&#34;</a></p>
		
		
		
			<h4>Previous article</h4>
			<p><a href="/spotlight-on-external-go-libraries">Spotlight on external Go libraries</a></p>
		
	
	
	<h4>Links</h4>
	<ul>
	<li><a href='//golang.org/'>golang.org</a></li>
	<li><a href='//golang.org/doc/install.html'>Install Go</a></li>
	<li><a href='//tour.golang.org/'>A Tour of Go</a></li>
	<li><a href='//golang.org/doc/'>Go Documentation</a></li>
	<li><a href='//groups.google.com/group/golang-nuts'>Go Mailing List</a></li>
	<li><a href='//plus.google.com/101406623878176903605'>Go on Google+</a></li>
	<li><a href='//plus.google.com/112164155169467723645/posts'>Go+ Community</a></li>
	<li><a href='//twitter.com/golang'>Go on Twitter</a></li>
	</ul>
	
	<p><a href="/index">Blog index</a></p>
</div>

<div id="content">
	<h1><a href="/">The Go Blog</a></h1>
	
	
	<div class="article">
		<h3 class="title"><a href="/profiling-go-programs">Profiling Go Programs</a></h3>
		<p class="date">24 June 2011</p>
		

  
  
    
      
        
  
  <p>
    At Scala Days 2011, Robert Hundt presented a paper titled


    <a href="http://research.google.com/pubs/pub37122.html" target="_blank">Loop Recognition in C++/Java/Go/Scala.</a>


    The paper implemented a specific loop finding algorithm, such as you might use


    in a flow analysis pass of a compiler, in C++, Go, Java, Scala, and then used


    those programs to draw conclusions about typical performance concerns in these


    languages.


    The Go program presented in that paper runs quite slowly, making it


    an excellent opportunity to demonstrate how to use Go&#39;s profiling tools to take


    a slow program and make it faster.
  </p>
  

      
        
  
  <p>
    <i>By using Go&#39;s profiling tools to identify and correct specific bottlenecks, we can make the Go loop finding program run an order of magnitude faster and use 6x less memory.</i>


    (Update: Due to recent optimizations of <code>libstdc++</code> in <code>gcc</code>, the memory reduction is now 3.7x.)
  </p>
  

      
        
  
  <p>
    Hundt&#39;s paper does not specify which versions of the C++, Go, Java, and Scala


    tools he used.


    In this blog post, we will be using the most recent weekly snapshot of the <code>6g</code>


    Go compiler and the version of <code>g++</code> that ships with the Ubuntu Natty


    distribution.


    (We will not be using Java or Scala, because we are not skilled at writing efficient


    programs in either of those languages, so the comparison would be unfair.


    Since C++ was the fastest language in the paper, the comparisons here with C++ should


    suffice.)


    (Update: In this updated post, we will be using the most recent development snapshot


    of the Go compiler on amd64 and the most recent version of <code>g++</code> -- 4.8.0, which was


    released in March 2013.)
  </p>
  

      
        
  
  <div class="code"><pre>$ go version
go version devel &#43;08d20469cc20 Tue Mar 26 08:27:18 2013 &#43;0100 linux/amd64
$ g&#43;&#43; --version
g&#43;&#43; (GCC) 4.8.0
Copyright (C) 2013 Free Software Foundation, Inc.
...
$</pre></div>
  

      
        
  
  <p>
    The programs are run on a computer with a 3.4GHz Core i7-2600 CPU and 16 GB of


    RAM running Gentoo Linux&#39;s 3.8.4-gentoo kernel.


    The machine is running with CPU frequency scaling disabled via
  </p>
  

      
        
  
  <div class="code"><pre>$ sudo bash
# for i in /sys/devices/system/cpu/cpu[0-7]
do
    echo performance &gt; $i/cpufreq/scaling_governor
done
#</pre></div>
  

      
        
  
  <p>
    We&#39;ve taken <a href="http://code.google.com/p/multi-language-bench/" target="_blank">Hundt&#39;s benchmark programs</a>


    in C++ and Go, combined each into a single source file, and removed all but one


    line of output.


    We&#39;ll time the program using Linux&#39;s <code>time</code> utility with a format that shows user time,


    system time, real time, and maximum memory usage:
  </p>
  

      
        
  
  <div class="code"><pre>$ cat xtime
#!/bin/sh
/usr/bin/time -f &#39;%Uu %Ss %er %MkB %C&#39; &#34;$@&#34;
$

$ make havlak1cc
g&#43;&#43; -O3 -o havlak1cc havlak1.cc
$ ./xtime ./havlak1cc
# of loops: 76002 (total 3800100)
loop-0, nest: 0, depth: 0
17.70u 0.05s 17.80r 715472kB ./havlak1cc
$

$ make havlak1
go build havlak1.go
$ ./xtime ./havlak1
# of loops: 76000 (including 1 artificial root node)
25.05u 0.11s 25.20r 1334032kB ./havlak1
$</pre></div>
  

      
        
  
  <p>
    The C++ program runs in 17.80 seconds and uses 700 MB of memory.


    The Go program runs in 25.20 seconds and uses 1302 MB of memory.


    (These measurements are difficult to reconcile with the ones in the paper, but the


    point of this post is to explore how to use `go tool pprof`, not to reproduce the


    results from the paper.)
  </p>
  

      
        
  
  <p>
    To start tuning the Go program, we have to enable profiling.


    If the code used the <a href="http://golang.org/pkg/testing/" target="_blank">Go testing package</a>&#39;s


    benchmarking support, we could use gotest&#39;s standard <code>-cpuprofile</code> and <code>-memprofile</code>


    flags.


    In a standalone program like this one, we have to import <code>runtime/pprof</code> and add a few


    lines of code:
  </p>
  

      
        
  
  <div class="code"><pre>var cpuprofile = flag.String(&#34;cpuprofile&#34;, &#34;&#34;, &#34;write cpu profile to file&#34;)

func main() {
    flag.Parse()
    if *cpuprofile != &#34;&#34; {
        f, err := os.Create(*cpuprofile)
        if err != nil {
            log.Fatal(err)
        }
        pprof.StartCPUProfile(f)
        defer pprof.StopCPUProfile()
    }
    ...</pre></div>
  

      
        
  
  <p>
    The new code defines a flag named <code>cpuprofile</code>, calls the


    <a href="http://golang.org/pkg/flag/" target="_blank">Go flag library</a> to parse the command line flags,


    and then, if the <code>cpuprofile</code> flag has been set on the command line,


    <a href="http://golang.org/pkg/runtime/pprof/#StartCPUProfile" target="_blank">starts CPU profiling</a>


    redirected to that file.


    The profiler requires a final call to


    <a href="http://golang.org/pkg/runtime/pprof/#StopCPUProfile" target="_blank"><code>StopCPUProfile</code></a> to


    flush any pending writes to the file before the program exits; we use <code>defer</code>


    to make sure this happens as <code>main</code> returns.
  </p>
  

      
        
  
  <p>
    After adding that code, we can run the program with the new <code>-cpuprofile</code> flag


    and then run `go tool pprof` to interpret the profile.
  </p>
  

      
        
  
  <div class="code"><pre>$ make havlak1.prof
./havlak1 -cpuprofile=havlak1.prof
# of loops: 76000 (including 1 artificial root node)
$ go tool pprof havlak1 havlak1.prof
Welcome to pprof!  For help, type &#39;help&#39;.
(pprof)</pre></div>
  

      
        
  
  <p>
    The `go tool pprof` program is a slight variant of


    <a href="https://code.google.com/p/gperftools/wiki/GooglePerformanceTools" target="_blank">Google&#39;s <code>pprof</code> C++ profiler</a>.


    The most important command is <code>topN</code>, which shows the top <code>N</code> samples in the profile:
  </p>
  

      
        
  
  <div class="code"><pre>(pprof) top10
Total: 2525 samples
     298  11.8%  11.8%      345  13.7% runtime.mapaccess1_fast64
     268  10.6%  22.4%     2124  84.1% main.FindLoops
     251   9.9%  32.4%      451  17.9% scanblock
     178   7.0%  39.4%      351  13.9% hash_insert
     131   5.2%  44.6%      158   6.3% sweepspan
     119   4.7%  49.3%      350  13.9% main.DFS
      96   3.8%  53.1%       98   3.9% flushptrbuf
      95   3.8%  56.9%       95   3.8% runtime.aeshash64
      95   3.8%  60.6%      101   4.0% runtime.settype_flush
      88   3.5%  64.1%      988  39.1% runtime.mallocgc</pre></div>
  

      
        
  
  <p>
    When CPU profiling is enabled, the Go program stops about 100 times per second


    and records a sample consisting of the program counters on the currently executing


    goroutine&#39;s stack.


    The profile has 2525 samples, so it was running for a bit over 25 seconds.


    In the `go tool pprof` output, there is a row for each function that appeared in


    a sample.


    The first two columns show the number of samples in which the function was running


    (as opposed to waiting for a called function to return), as a raw count and as a


    percentage of total samples.


    The <code>runtime.mapaccess1_fast64</code> function was running during 298 samples, or 11.8%.


    The <code>top10</code> output is sorted by this sample count.


    The third column shows the running total during the listing:


    the first three rows account for 32.4% of the samples.


    The fourth and fifth columns show the number of samples in which the function appeared


    (either running or waiting for a called function to return).


    The <code>main.FindLoops</code> function was running in 10.6% of the samples, but it was on the


    call stack (it or functions it called were running) in 84.1% of the samples.
  </p>
  

      
        
  
  <p>
    To sort by the fourth and fifth columns, use the <code>-cum</code> (for cumulative) flag:
  </p>
  

      
        
  
  <div class="code"><pre>(pprof) top5 -cum
Total: 2525 samples
       0   0.0%   0.0%     2144  84.9% gosched0
       0   0.0%   0.0%     2144  84.9% main.main
       0   0.0%   0.0%     2144  84.9% runtime.main
       0   0.0%   0.0%     2124  84.1% main.FindHavlakLoops
     268  10.6%  10.6%     2124  84.1% main.FindLoops
(pprof) top5 -cum</pre></div>
  

      
        
  
  <p>
    In fact the total for <code>main.FindLoops</code> and <code>main.main</code> should have been 100%, but


    each stack sample only includes the bottom 100 stack frames; during about a quarter


    of the samples, the recursive <code>main.DFS</code> function was more than 100 frames deeper


    than <code>main.main</code> so the complete trace was truncated.
  </p>
  

      
        
  
  <p>
    The stack trace samples contain more interesting data about function call relationships


    than the text listings can show.


    The <code>web</code> command writes a graph of the profile data in SVG format and opens it in a web


    browser.


    (There is also a <code>gv</code> command that writes PostScript and opens it in Ghostview.


    For either command, you need <a href="http://www.graphviz.org/" target="_blank">graphviz</a> installed.)
  </p>
  

      
        
  
  <div class="code"><pre>(pprof) web</pre></div>
  

      
        
  
  <p>
    A small fragment of


    <a href="http://benchgraffiti.googlecode.com/hg/havlak/havlak1.svg" target="_blank">the full graph</a> looks like:
  </p>
  

      
        
<div class="image">
  <img src="profiling-go-programs_havlak1a-75.png">
</div>

      
        
  
  <p>
    Each box in the graph corresponds to a single function, and the boxes are sized


    according to the number of samples in which the function was running.


    An edge from box X to box Y indicates that X calls Y; the number along the edge is


    the number of times that call appears in a sample.


    If a call appears multiple times in a single sample, such as during recursive function


    calls, each appearance counts toward the edge weight.


    That explains the 21342 on the self-edge from <code>main.DFS</code> to itself.
  </p>
  

      
        
  
  <p>
    Just at a glance, we can see that the program spends much of its time in hash


    operations, which correspond to use of Go&#39;s <code>map</code> values.


    We can tell <code>web</code> to use only samples that include a specific function, such as


    <code>runtime.mapaccess1_fast64</code>, which clears some of the noise from the graph:
  </p>
  

      
        
  
  <div class="code"><pre>(pprof) web mapaccess1</pre></div>
  

      
        
<div class="image">
  <img src="profiling-go-programs_havlak1-hash_lookup-75.png">
</div>

      
        
  
  <p>
    If we squint, we can see that the calls to <code>runtime.mapaccess1_fast64</code> are being


    made by <code>main.FindLoops</code> and <code>main.DFS</code>.
  </p>
  

      
        
  
  <p>
    Now that we have a rough idea of the big picture, it&#39;s time to zoom in on a particular


    function.


    Let&#39;s look at <code>main.DFS</code> first, just because it is a shorter function:
  </p>
  

      
        
  
  <div class="code"><pre>(pprof) list DFS
Total: 2525 samples
ROUTINE ====================== main.DFS in /home/rsc/g/benchgraffiti/havlak/havlak1.go
   119    697 Total samples (flat / cumulative)
     3      3  240: func DFS(currentNode *BasicBlock, nodes []*UnionFindNode, number map[*BasicBlock]int, last []int, current int) int {
     1      1  241:     nodes[current].Init(currentNode, current)
     1     37  242:     number[currentNode] = current
     .      .  243:
     1      1  244:     lastid := current
    89     89  245:     for _, target := range currentNode.OutEdges {
     9    152  246:             if number[target] == unvisited {
     7    354  247:                     lastid = DFS(target, nodes, number, last, lastid&#43;1)
     .      .  248:             }
     .      .  249:     }
     7     59  250:     last[number[currentNode]] = lastid
     1      1  251:     return lastid
(pprof)</pre></div>
  

      
        
  
  <p>
    The listing shows the source code for the <code>DFS</code> function (really, for every function


    matching the regular expression <code>DFS</code>).


    The first three columns are the number of samples taken while running that line, the


    number of samples taken while running that line or in code called from that line, and


    the line number in the file.


    The related command <code>disasm</code> shows a disassembly of the function instead of a source


    listing; when there are enough samples this can help you see which instructions are


    expensive.


    The <code>weblist</code> command mixes the two modes: it shows


    <a href="http://benchgraffiti.googlecode.com/hg/havlak/havlak1.html" target="_blank">a source listing in which clicking a line shows the disassembly</a>.
  </p>
  

      
        
  
  <p>
    Since we already know that the time is going into map lookups implemented by the


    hash runtime functions, we care most about the second column.


    A large fraction of time is spent in recursive calls to <code>DFS</code> (line 247), as would be


    expected from a recursive traversal.


    Excluding the recursion, it looks like the time is going into the accesses to the


    <code>number</code> map on lines 242, 246, and 250.


    For that particular lookup, a map is not the most efficient choice.


    Just as they would be in a compiler, the basic block structures have unique sequence


    numbers assigned to them.


    Instead of using a <code>map[*BasicBlock]int</code> we can use a <code>[]int</code>, a slice indexed by the


    block number.


    There&#39;s no reason to use a map when an array or slice will do.
  </p>
  

      
        
  
  <p>
    Changing <code>number</code> from a map to a slice requires editing seven lines in the program


    and cut its run time by nearly a factor of two:
  </p>
  

      
        
  
  <div class="code"><pre>$ make havlak2
go build havlak2.go
$ ./xtime ./havlak2
# of loops: 76000 (including 1 artificial root node)
16.55u 0.11s 16.69r 1321008kB ./havlak2
$</pre></div>
  

      
        
  
  <p>
    (See the <a href="http://code.google.com/p/benchgraffiti/source/diff?name=34f7624bb2e2&amp;r=240c155236f9&amp;format=unidiff&amp;path=/havlak/havlak.go" target="_blank">diff between <code>havlak1</code> and <code>havlak2</code></a>)
  </p>
  

      
        
  
  <p>
    We can run the profiler again to confirm that <code>main.DFS</code> is no longer a significant


    part of the run time:
  </p>
  

      
        
  
  <div class="code"><pre>$ make havlak2.prof
./havlak2 -cpuprofile=havlak2.prof
# of loops: 76000 (including 1 artificial root node)
$ go tool pprof havlak2 havlak2.prof
Welcome to pprof!  For help, type &#39;help&#39;.
(pprof)
(pprof) top5
Total: 1652 samples
     197  11.9%  11.9%      382  23.1% scanblock
     189  11.4%  23.4%     1549  93.8% main.FindLoops
     130   7.9%  31.2%      152   9.2% sweepspan
     104   6.3%  37.5%      896  54.2% runtime.mallocgc
      98   5.9%  43.5%      100   6.1% flushptrbuf
(pprof)</pre></div>
  

      
        
  
  <p>
    The entry <code>main.DFS</code> no longer appears in the profile, and the rest of the program


    runtime has dropped too.


    Now the program is spending most of its time allocating memory and garbage collecting


    (<code>runtime.mallocgc</code>, which both allocates and runs periodic garbage collections,


    accounts for 54.2% of the time).


    To find out why the garbage collector is running so much, we have to find out what is


    allocating memory.


    One way is to add memory profiling to the program.


    We&#39;ll arrange that if the <code>-memprofile</code> flag is supplied, the program stops after one


    iteration of the loop finding, writes a memory profile, and exits:
  </p>
  

      
        
  
  <div class="code"><pre>var memprofile = flag.String(&#34;memprofile&#34;, &#34;&#34;, &#34;write memory profile to this file&#34;)
...

    FindHavlakLoops(cfgraph, lsgraph)
    if *memprofile != &#34;&#34; {
        f, err := os.Create(*memprofile)
        if err != nil {
            log.Fatal(err)
        }
        pprof.WriteHeapProfile(f)
        f.Close()
        return
    }</pre></div>
  

      
        
  
  <p>
    We invoke the program with <code>-memprofile</code> flag to write a profile:
  </p>
  

      
        
  
  <div class="code"><pre>$ make havlak3.mprof
go build havlak3.go
./havlak3 -memprofile=havlak3.mprof
$</pre></div>
  

      
        
  
  <p>
    (See the <a href="http://code.google.com/p/benchgraffiti/source/diff?name=240c155236f9&amp;r=796913012f93&amp;format=unidiff&amp;path=/havlak/havlak.go" target="_blank">diff from havlak2</a>)
  </p>
  

      
        
  
  <p>
    We use `go tool pprof` exactly the same way. Now the samples we are examining are


    memory allocations, not clock ticks.
  </p>
  

      
        
  
  <div class="code"><pre>$ go tool pprof havlak3 havlak3.mprof
Adjusting heap profiles for 1-in-524288 sampling rate
Welcome to pprof!  For help, type &#39;help&#39;.
(pprof) top5
Total: 82.4 MB
    56.3  68.4%  68.4%     56.3  68.4% main.FindLoops
    17.6  21.3%  89.7%     17.6  21.3% main.(*CFG).CreateNode
     8.0   9.7%  99.4%     25.6  31.0% main.NewBasicBlockEdge
     0.5   0.6% 100.0%      0.5   0.6% itab
     0.0   0.0% 100.0%      0.5   0.6% fmt.init
(pprof)</pre></div>
  

      
        
  
  <p>
    The command `go tool pprof` reports that <code>FindLoops</code> has allocated approximately


    56.3 of the 82.4 MB in use; <code>CreateNode</code> accounts for another 17.6 MB.


    To reduce overhead, the memory profiler only records information for approximately


    one block per half megabyte allocated (the “1-in-524288 sampling rate”), so these


    are approximations to the actual counts.
  </p>
  

      
        
  
  <p>
    To find the memory allocations, we can list those functions.
  </p>
  

      
        
  
  <div class="code"><pre>(pprof) list FindLoops
Total: 82.4 MB
ROUTINE ====================== main.FindLoops in /home/rsc/g/benchgraffiti/havlak/havlak3.go
  56.3   56.3 Total MB (flat / cumulative)
...
   1.9    1.9  268:     nonBackPreds := make([]map[int]bool, size)
   5.8    5.8  269:     backPreds := make([][]int, size)
     .      .  270:
   1.9    1.9  271:     number := make([]int, size)
   1.9    1.9  272:     header := make([]int, size, size)
   1.9    1.9  273:     types := make([]int, size, size)
   1.9    1.9  274:     last := make([]int, size, size)
   1.9    1.9  275:     nodes := make([]*UnionFindNode, size, size)
     .      .  276:
     .      .  277:     for i := 0; i &lt; size; i&#43;&#43; {
   9.5    9.5  278:             nodes[i] = new(UnionFindNode)
     .      .  279:     }
...
     .      .  286:     for i, bb := range cfgraph.Blocks {
     .      .  287:             number[bb.Name] = unvisited
  29.5   29.5  288:             nonBackPreds[i] = make(map[int]bool)
     .      .  289:     }
...</pre></div>
  

      
        
  
  <p>
    It looks like the current bottleneck is the same as the last one: using maps where


    simpler data structures suffice.


    <code>FindLoops</code> is allocating about 29.5 MB of maps.
  </p>
  

      
        
  
  <p>
    As an aside, if we run `go tool pprof` with the <code>--inuse_objects</code> flag, it will


    report allocation counts instead of sizes:
  </p>
  

      
        
  
  <div class="code"><pre>$ go tool pprof --inuse_objects havlak3 havlak3.mprof
Adjusting heap profiles for 1-in-524288 sampling rate
Welcome to pprof!  For help, type &#39;help&#39;.
(pprof) list FindLoops
Total: 1763108 objects
ROUTINE ====================== main.FindLoops in /home/rsc/g/benchgraffiti/havlak/havlak3.go
720903 720903 Total objects (flat / cumulative)
...
     .      .  277:     for i := 0; i &lt; size; i&#43;&#43; {
311296 311296  278:             nodes[i] = new(UnionFindNode)
     .      .  279:     }
     .      .  280:
     .      .  281:     // Step a:
     .      .  282:     //   - initialize all nodes as unvisited.
     .      .  283:     //   - depth-first traversal and numbering.
     .      .  284:     //   - unreached BB&#39;s are marked as dead.
     .      .  285:     //
     .      .  286:     for i, bb := range cfgraph.Blocks {
     .      .  287:             number[bb.Name] = unvisited
409600 409600  288:             nonBackPreds[i] = make(map[int]bool)
     .      .  289:     }
...
(pprof)</pre></div>
  

      
        
  
  <p>
    Since the ~200,000 maps account for 29.5 MB, it looks like the initial map allocation


    takes about 150 bytes.


    That&#39;s reasonable when a map is being used to hold key-value pairs, but not when a map


    is being used as a stand-in for a simple set, as it is here.
  </p>
  

      
        
  
  <p>
    Instead of using a map, we can use a simple slice to list the elements.


    In all but one of the cases where maps are being used, it is impossible for the algorithm


    to insert a duplicate element.


    In the one remaining case, we can write a simple variant of the <code>append</code> built-in function:
  </p>
  

      
        
  
  <div class="code"><pre>func appendUnique(a []int, x int) []int {
    for _, y := range a {
        if x == y {
            return a
        }
    }
    return append(a, x)
}</pre></div>
  

      
        
  
  <p>
    In addition to writing that function, changing the Go program to use slices instead


    of maps requires changing just a few lines of code.
  </p>
  

      
        
  
  <div class="code"><pre>$ make havlak4
go build havlak4.go
$ ./xtime ./havlak4
# of loops: 76000 (including 1 artificial root node)
11.84u 0.08s 11.94r 810416kB ./havlak4
$</pre></div>
  

      
        
  
  <p>
    (See the <a href="http://code.google.com/p/benchgraffiti/source/diff?name=796913012f93&amp;r=d856c2f698c1&amp;format=unidiff&amp;path=/havlak/havlak.go" target="_blank">diff from havlak3</a>)
  </p>
  

      
        
  
  <p>
    We&#39;re now at 2.11x faster than when we started. Let&#39;s look at a CPU profile again.
  </p>
  

      
        
  
  <div class="code"><pre>$ make havlak4.prof
./havlak4 -cpuprofile=havlak4.prof
# of loops: 76000 (including 1 artificial root node)
$ go tool pprof havlak4 havlak4.prof
Welcome to pprof!  For help, type &#39;help&#39;.
(pprof) top10
Total: 1173 samples
     205  17.5%  17.5%     1083  92.3% main.FindLoops
     138  11.8%  29.2%      215  18.3% scanblock
      88   7.5%  36.7%       96   8.2% sweepspan
      76   6.5%  43.2%      597  50.9% runtime.mallocgc
      75   6.4%  49.6%       78   6.6% runtime.settype_flush
      74   6.3%  55.9%       75   6.4% flushptrbuf
      64   5.5%  61.4%       64   5.5% runtime.memmove
      63   5.4%  66.8%      524  44.7% runtime.growslice
      51   4.3%  71.1%       51   4.3% main.DFS
      50   4.3%  75.4%      146  12.4% runtime.MCache_Alloc
(pprof)</pre></div>
  

      
        
  
  <p>
    Now memory allocation and the consequent garbage collection (<code>runtime.mallocgc</code>)


    accounts for 50.9% of our run time.


    Another way to look at why the system is garbage collecting is to look at the


    allocations that are causing the collections, the ones that spend most of the time


    in <code>mallocgc</code>:
  </p>
  

      
        
  
  <div class="code"><pre>(pprof) web mallocgc</pre></div>
  

      
        
<div class="image">
  <img src="profiling-go-programs_havlak4a-mallocgc.png">
</div>

      
        
  
  <p>
    It&#39;s hard to tell what&#39;s going on in that graph, because there are many nodes with


    small sample numbers obscuring the big ones.


    We can tell `go tool pprof` to ignore nodes that don&#39;t account for at least 10% of


    the samples:
  </p>
  

      
        
  
  <div class="code"><pre>$ go tool pprof --nodefraction=0.1 havlak4 havlak4.prof
Welcome to pprof!  For help, type &#39;help&#39;.
(pprof) web mallocgc</pre></div>
  

      
        
<div class="image">
  <img src="profiling-go-programs_havlak4a-mallocgc-trim.png">
</div>

      
        
  
  <p>
    We can follow the thick arrows easily now, to see that <code>FindLoops</code> is triggering


    most of the garbage collection.


    If we list <code>FindLoops</code> we can see that much of it is right at the beginning:
  </p>
  

      
        
  
  <div class="code"><pre>(pprof) list FindLoops
...
     .      .  270: func FindLoops(cfgraph *CFG, lsgraph *LSG) {
     .      .  271:     if cfgraph.Start == nil {
     .      .  272:             return
     .      .  273:     }
     .      .  274:
     .      .  275:     size := cfgraph.NumNodes()
     .      .  276:
     .    145  277:     nonBackPreds := make([][]int, size)
     .      9  278:     backPreds := make([][]int, size)
     .      .  279:
     .      1  280:     number := make([]int, size)
     .     17  281:     header := make([]int, size, size)
     .      .  282:     types := make([]int, size, size)
     .      .  283:     last := make([]int, size, size)
     .      .  284:     nodes := make([]*UnionFindNode, size, size)
     .      .  285:
     .      .  286:     for i := 0; i &lt; size; i&#43;&#43; {
     2     79  287:             nodes[i] = new(UnionFindNode)
     .      .  288:     }
...
(pprof)</pre></div>
  

      
        
  
  <p>
    Every time <code>FindLoops</code> is called, it allocates some sizable bookkeeping structures.


    Since the benchmark calls <code>FindLoops</code> 50 times, these add up to a significant amount


    of garbage, so a significant amount of work for the garbage collector.
  </p>
  

      
        
  
  <p>
    Having a garbage-collected language doesn&#39;t mean you can ignore memory allocation


    issues.


    In this case, a simple solution is to introduce a cache so that each call to <code>FindLoops</code>


    reuses the previous call&#39;s storage when possible.


    (In fact, in Hundt&#39;s paper, he explains that the Java program needed just this change to


    get anything like reasonable performance, but he did not make the same change in the


    other garbage-collected implementations.)
  </p>
  

      
        
  
  <p>
    We&#39;ll add a global <code>cache</code> structure:
  </p>
  

      
        
  
  <div class="code"><pre>var cache struct {
    size int
    nonBackPreds [][]int
    backPreds [][]int
    number []int
    header []int
    types []int
    last []int
    nodes []*UnionFindNode
}</pre></div>
  

      
        
  
  <p>
    and then have <code>FindLoops</code> consult it as a replacement for allocation:
  </p>
  

      
        
  
  <div class="code"><pre>if cache.size &lt; size {
    cache.size = size
    cache.nonBackPreds = make([][]int, size)
    cache.backPreds = make([][]int, size)
    cache.number = make([]int, size)
    cache.header = make([]int, size)
    cache.types = make([]int, size)
    cache.last = make([]int, size)
    cache.nodes = make([]*UnionFindNode, size)
    for i := range cache.nodes {
        cache.nodes[i] = new(UnionFindNode)
    }
}

nonBackPreds := cache.nonBackPreds[:size]
for i := range nonBackPreds {
    nonBackPreds[i] = nonBackPreds[i][:0]
}
backPreds := cache.backPreds[:size]
for i := range nonBackPreds {
    backPreds[i] = backPreds[i][:0]
}
number := cache.number[:size]
header := cache.header[:size]
types := cache.types[:size]
last := cache.last[:size]
nodes := cache.nodes[:size]</pre></div>
  

      
        
  
  <p>
    Such a global variable is bad engineering practice, of course: it means that


    concurrent calls to <code>FindLoops</code> are now unsafe.


    For now, we are making the minimal possible changes in order to understand what


    is important for the performance of our program; this change is simple and mirrors


    the code in the Java implementation.


    The final version of the Go program will use a separate <code>LoopFinder</code> instance to


    track this memory, restoring the possibility of concurrent use.
  </p>
  

      
        
  
  <div class="code"><pre>$ make havlak5
go build havlak5.go
$ ./xtime ./havlak5
# of loops: 76000 (including 1 artificial root node)
8.03u 0.06s 8.11r 770352kB ./havlak5
$</pre></div>
  

      
        
  
  <p>
    (See the <a href="http://code.google.com/p/benchgraffiti/source/diff?name=d856c2f698c1&amp;r=5ce46b0ee1db&amp;format=unidiff&amp;path=/havlak/havlak.go" target="_blank">diff from havlak4</a>)
  </p>
  

      
        
  
  <p>
    There&#39;s more we can do to clean up the program and make it faster, but none of


    it requires profiling techniques that we haven&#39;t already shown.


    The work list used in the inner loop can be reused across iterations and across


    calls to <code>FindLoops</code>, and it can be combined with the separate “node pool” generated


    during that pass.


    Similarly, the loop graph storage can be reused on each iteration instead of reallocated.


    In addition to these performance changes, the


    <a href="http://code.google.com/p/benchgraffiti/source/browse/havlak/havlak6.go" target="_blank">final version</a>


    is written using idiomatic Go style, using data structures and methods.


    The stylistic changes have only a minor effect on the run time: the algorithm and


    constraints are unchanged.
  </p>
  

      
        
  
  <p>
    The final version runs in 2.29 seconds and uses 351 MB of memory:
  </p>
  

      
        
  
  <div class="code"><pre>$ make havlak6
go build havlak6.go
$ ./xtime ./havlak6
# of loops: 76000 (including 1 artificial root node)
2.26u 0.02s 2.29r 360224kB ./havlak6
$</pre></div>
  

      
        
  
  <p>
    That&#39;s 11 times faster than the program we started with.


    Even if we disable reuse of the generated loop graph, so that the only cached memory


    is the loop finding bookeeping, the program still runs 6.7x faster than the original


    and uses 1.5x less memory.
  </p>
  

      
        
  
  <div class="code"><pre>$ ./xtime ./havlak6 -reuseloopgraph=false
# of loops: 76000 (including 1 artificial root node)
3.69u 0.06s 3.76r 797120kB ./havlak6 -reuseloopgraph=false
$</pre></div>
  

      
        
  
  <p>
    Of course, it&#39;s no longer fair to compare this Go program to the original C++


    program, which used inefficient data structures like `set`s where `vector`s would


    be more appropriate.


    As a sanity check, we translated the final Go program into


    <a href="http://code.google.com/p/benchgraffiti/source/browse/havlak/havlak6.cc" target="_blank">equivalent C++ code</a>.


    Its execution time is similar to the Go program&#39;s:
  </p>
  

      
        
  
  <div class="code"><pre>$ make havlak6cc
g&#43;&#43; -O3 -o havlak6cc havlak6.cc
$ ./xtime ./havlak6cc
# of loops: 76000 (including 1 artificial root node)
1.99u 0.19s 2.19r 387936kB ./havlak6cc</pre></div>
  

      
        
  
  <p>
    The Go program runs almost as fast as the C++ program.


    As the C++ program is using automatic deletes and allocation instead of an explicit


    cache, the C++ program a bit shorter and easier to write, but not dramatically so:
  </p>
  

      
        
  
  <div class="code"><pre>$ wc havlak6.cc; wc havlak6.go
 401 1220 9040 havlak6.cc
 461 1441 9467 havlak6.go
$</pre></div>
  

      
        
  
  <p>
    (See <a href="http://code.google.com/p/benchgraffiti/source/browse/havlak/havlak6.cc" target="_blank">havlak6.cc</a>


    and <a href="http://code.google.com/p/benchgraffiti/source/browse/havlak/havlak6.go" target="_blank">havlak6.go</a>)
  </p>
  

      
        
  
  <p>
    Benchmarks are only as good as the programs they measure.


    We used `go tool pprof` to study an inefficient Go program and then to improve its


    performance by an order of magnitude and to reduce its memory usage by a factor of 3.7.


    A subsequent comparison with an equivalently optimized C++ program shows that Go can be


    competitive with C++ when programmers are careful about how much garbage is generated


    by inner loops.
  </p>
  

      
        
  
  <p>
    The program sources, Linux x86-64 binaries, and profiles used to write this post


    are available in the <a href="http://code.google.com/p/benchgraffiti/" target="_blank">benchgraffiti project on Google Code</a>.
  </p>
  

      
        
  
  <p>
    As mentioned above, <a href="http://golang.org/cmd/go/#Test_packages" target="_blank">`go test`</a> includes


    these profiling flags already: define a


    <a href="http://golang.org/pkg/testing/" target="_blank">benchmark function</a> and you&#39;re all set.


    There is also a standard HTTP interface to profiling data. In an HTTP server, adding
  </p>
  

      
        
  
  <div class="code"><pre>import _ &#34;net/http/pprof&#34;</pre></div>
  

      
        
  
  <p>
    will install handlers for a few URLs under <code>/debug/pprof/</code>.


    Then you can run `go tool pprof` with a single argument—the URL to your server&#39;s


    profiling data and it will download and examine a live profile.
  </p>
  

      
        
  
  <div class="code"><pre>go tool pprof http://localhost:6060/debug/pprof/profile   # 30-second CPU profile
go tool pprof http://localhost:6060/debug/pprof/heap      # heap profile
go tool pprof http://localhost:6060/debug/pprof/block     # goroutine blocking profile</pre></div>
  

      
        
  
  <p>
    The goroutine blocking profile will be explained in a future post. Stay tuned.
  </p>
  

      
    
  


		
			<p class="author">By Russ Cox, July 2011; updated by Shenghou Ma, May 2013</p>
		
	</div>

	
		<h2>Related articles</h2>
		<ul>
		
			<li><a href="/generate">Generating code</a></li>
		
			<li><a href="/race-detector">Introducing the Go Race Detector</a></li>
		
			<li><a href="/go-maps-in-action">Go maps in action</a></li>
		
			<li><a href="/go-fmt-your-code">go fmt your code</a></li>
		
			<li><a href="/organizing-go-code">Organizing Go code</a></li>
		
			<li><a href="/debugging-go-programs-with-gnu-debugger">Debugging Go programs with the GNU Debugger</a></li>
		
			<li><a href="/go-imagedraw-package">The Go image/draw package</a></li>
		
			<li><a href="/go-image-package">The Go image package</a></li>
		
			<li><a href="/laws-of-reflection">The Laws of Reflection</a></li>
		
			<li><a href="/error-handling-and-go">Error handling and Go</a></li>
		
			<li><a href="/first-class-functions-in-go-and-new-go">&#34;First Class Functions in Go&#34;</a></li>
		
			<li><a href="/gif-decoder-exercise-in-go-interfaces">A GIF decoder: an exercise in Go interfaces</a></li>
		
			<li><a href="/introducing-gofix">Introducing Gofix</a></li>
		
			<li><a href="/godoc-documenting-go-code">Godoc: documenting Go code</a></li>
		
			<li><a href="/gobs-of-data">Gobs of data</a></li>
		
			<li><a href="/c-go-cgo">C? Go? Cgo!</a></li>
		
			<li><a href="/json-and-go">JSON and Go</a></li>
		
			<li><a href="/go-slices-usage-and-internals">Go Slices: usage and internals</a></li>
		
			<li><a href="/go-concurrency-patterns-timing-out-and">Go Concurrency Patterns: Timing out, moving on</a></li>
		
			<li><a href="/defer-panic-and-recover">Defer, Panic, and Recover</a></li>
		
			<li><a href="/share-memory-by-communicating">Share Memory By Communicating</a></li>
		
			<li><a href="/json-rpc-tale-of-interfaces">JSON-RPC: a tale of interfaces</a></li>
		
		</ul>
	

</div>

<div id="footer">
	<p>
	Except as
	<a href="https://developers.google.com/site-policies#restrictions">noted</a>,
	the content of this page is licensed under the Creative Commons
	Attribution 3.0 License,<br>
	and code is licensed under a <a href="//golang.org/LICENSE">BSD license</a>.<br>
	<a href="//golang.org/doc/tos.html">Terms of Service</a> | 
	<a href="//www.google.com/intl/en/policies/privacy/">Privacy Policy</a>
	</p>
</div>

</div>
</div>

<script type="text/javascript">
(function() {
  var ga = document.createElement("script"); ga.type = "text/javascript"; ga.async = true;
  ga.src = ("https:" == document.location.protocol ? "https://ssl" : "http://www") + ".google-analytics.com/ga.js";
  var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(ga, s);
})();
</script>
</body>
<script src="/lib/godoc/jquery.js"></script>
<script src="/lib/godoc/playground.js"></script>
<script src="/lib/godoc/play.js"></script>
<script src="/lib/godoc/godocs.js"></script>
<script>
$(function() {
	
	$('.playground > pre.numbers, .code > pre.numbers').each(function() {
		var $spans = $(this).find('> span');

		
		var max = 0;
		$spans.each(function() {
			var n = $(this).attr('num')*1;
			if (n > max) max = n;
		});
		var width = 2;
		while (max > 10) {
			max = max / 10;
			width++;
		}

		
		$spans.each(function() {
			var n = $(this).attr('num')+' ';
			while (n.length < width) n = ' '+n;
			$('<span class="number">').text(n).insertBefore(this);
		});
	});

	initPlayground(new HTTPTransport());
});
</script>
</html>
